{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0008, 0016) SOP Class UID                       UI: Secondary Capture Image Storage\n",
       "(0008, 0018) SOP Instance UID                    UI: 1.3.6.1.4.1.11129.5.5.110503645592756492463169821050252582267888\n",
       "(0008, 0060) Modality                            CS: 'DX'\n",
       "(0008, 1030) Study Description                   LO: 'No Finding'\n",
       "(0010, 0020) Patient ID                          LO: '2'\n",
       "(0010, 0040) Patient's Sex                       CS: 'M'\n",
       "(0010, 1010) Patient's Age                       AS: '81'\n",
       "(0018, 0015) Body Part Examined                  CS: 'CHEST'\n",
       "(0018, 5100) Patient Position                    CS: 'PA'\n",
       "(0020, 000d) Study Instance UID                  UI: 1.3.6.1.4.1.11129.5.5.112507010803284478207522016832191866964708\n",
       "(0020, 000e) Series Instance UID                 UI: 1.3.6.1.4.1.11129.5.5.112630850362182468372440828755218293352329\n",
       "(0028, 0002) Samples per Pixel                   US: 1\n",
       "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028, 0010) Rows                                US: 1024\n",
       "(0028, 0011) Columns                             US: 1024\n",
       "(0028, 0100) Bits Allocated                      US: 8\n",
       "(0028, 0101) Bits Stored                         US: 8\n",
       "(0028, 0102) High Bit                            US: 7\n",
       "(0028, 0103) Pixel Representation                US: 0\n",
       "(7fe0, 0010) Pixel Data                          OW: Array of 1048576 elements"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pydicom.read_file('test1.dcm')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)       \n",
    "    \n",
    "    # Reference : https://knowledge.udacity.com/questions/196289\n",
    "    modality = ds.Modality\n",
    "    position = ds.PatientPosition\n",
    "    part = ds.BodyPartExamined\n",
    "    \n",
    "    if modality != 'DX':\n",
    "        print('Image modality not supported')\n",
    "        return\n",
    "    \n",
    "    if position not in ['PA', 'AP']:\n",
    "        print('Patient position not supported')\n",
    "        return\n",
    "    \n",
    "    if part != 'CHEST':\n",
    "        print('Model not trained for given body part')\n",
    "        return\n",
    "    \n",
    "    img = ds.pixel_array\n",
    "    return img\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img,img_mean,img_std,img_size): \n",
    "    \n",
    "    proc_img = (img-img_mean) / img_std\n",
    "    proc_img = skimage.transform.resize(proc_img, img_size)\n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    \n",
    "    # Reference : https://knowledge.udacity.com/questions/204967\n",
    "    with open(model_path, 'r') as f:\n",
    "        model = tf.keras.models.model_from_json(f.read())\n",
    "    model.load_weights(weight_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    pred = model.predict(img)\n",
    "    prediction = 'No Pnuemonia'\n",
    "    \n",
    "    if pred > thresh:\n",
    "        prediction = 'Pneumonia'  \n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file test1.dcm ...\n",
      "Pneumonia\n",
      "Load file test2.dcm ...\n",
      "Pneumonia\n",
      "Load file test3.dcm ...\n",
      "Pneumonia\n",
      "Load file test4.dcm ...\n",
      "Model not trained for given body part\n",
      "Load file test5.dcm ...\n",
      "Image modality not supported\n",
      "Load file test6.dcm ...\n",
      "Patient position not supported\n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = './model.json'\n",
    "weight_path = './xray_class_my_model.best.hdf5'\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "img_mean = 0 # loads the mean image value they used during training preprocessing\n",
    "img_std = 255 # loads the std dev image value they used during training preprocessing\n",
    "\n",
    "my_model = load_model(model_path, weight_path) #loads model\n",
    "thresh = 0.349681 #loads the threshold they chose for model classification \n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img,img_mean,img_std,IMG_SIZE)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
